<!-- SVG Header -->
<p align="center">
  <img src="banner.jpg" alt="Header Image" />
</p>

# Hi there, welcome to my GitHub page! üëã

I'm Joseph, an AI Engineer and Robotics Software Developer with a passion for intelligent field robotics and deep learning. üöÄ I love building intelligent systems and sharing knowledge with the community. From autonomous robotic exploration to multi-robot control and developing deep learning models, I'm always up for a challenge!

![Profile Views](https://komarev.com/ghpvc/?username=adeola-jo&style=flat-square)

## üöÄ Technologies & Tools

<p align="left">
  <img src="https://img.shields.io/badge/ROS-22314E?style=for-the-badge&logo=ros&logoColor=white" alt="ROS"/>
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" alt="Python"/>
  <img src="https://img.shields.io/badge/C++-00599C?style=for-the-badge&logo=c%2B%2B&logoColor=white" alt="C++"/>
  <img src="https://img.shields.io/badge/Ubuntu-E95420?style=for-the-badge&logo=ubuntu&logoColor=white" alt="Ubuntu"/>
  <img src="https://img.shields.io/badge/Git-F05032?style=for-the-badge&logo=git&logoColor=white" alt="Git"/>
  <img src="https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white" alt="GitHub"/>
  <img src="https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white" alt="Docker"/>
</p>

## üåê Connect with Me

<p align="left">
  <a href="https://www.linkedin.com/in/adeola-joseph" target="_blank">
    <img src="https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white" alt="LinkedIn"/>
  </a>
  <!-- <a href="https://twitter.com/yourprofile" target="_blank">
    <img src="https://img.shields.io/badge/Twitter-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white" alt="Twitter"/>
  </a>
  -->
  <a href="mailto:adeolajosepholoruntoba@gmail.com">
    <img src="https://img.shields.io/badge/Email-D14836?style=for-the-badge&logo=gmail&logoColor=white" alt="Email"/>
  </a>
  <a href="https://adeola-jo.github.io" target="_blank">
    <img src="https://img.shields.io/badge/Website-4285F4?style=for-the-badge&logo=google-chrome&logoColor=white" alt="Website"/>
  </a>
</p>


## üìù Latest Blog Posts

- **[Introduction to Reinforcement Learning](https://yourwebsite.com/blog/post1)**

Feel free to reach out if you have any questions or just want to connect!

---

![GitHub Stats](https://github-readme-stats.vercel.app/api?username=adeola-jo&show_icons=true&theme=radical)
![Top Languages](https://github-readme-stats.vercel.app/api/top-langs/?username=adeola-jo&layout=compact&theme=radical)


## üìÇ Recent Projects

- **[Robust Coordination and Control of Multi-Robot Systems Using Consensus Protocols](https://github.com/MosesEbere/multi-robot-consensus)**:
  
  This project focused on developing and implementing consensus protocol-based control strategies for multi-robot systems, particularly for rendezvous and formation control. Using graph theory, we modeled and controlled the dynamics of robot swarms in both distributed and semi-distributed settings. The experimental analysis was conducted in a dual-simulation environment, integrating Pygame and Stage Simulator with ROS, to assess the effectiveness of these protocols.

- **[Controlling a Swarm of Robots in a Simulator Stage using Reynolds‚Äô Rules](https://github.com/yourusername/project2)**:
  
  In this project, we programmed virtual robots to move together like a coordinated swarm, inspired by the natural movements of birds and fish and Craig Reynolds' behavioral rules. By applying simple principles like Separation, Alignment, and Cohesion, we created a simulation where the robots navigated collectively, avoided obstacles, and reached their destinations together.



# üìÇ All Projects

## Robotics and Control

- **[Design of an Attitude and Position PID Controller for a Quadcopter](https://github.com/yourusername/quadcopter-pid-controller)**:
  
  A PID control system for quadcopter attitude and position control. Implements separate controllers for roll, pitch, yaw, and altitude. Addresses challenges in tuning gains for stable flight in various conditions and disturbance rejection.

- **[Pick and Place Application with the St√§ubli TS60 Robot](https://github.com/yourusername/staubli-ts60-pick-place)**:
  
  A pick and place system implementation in VAL3 languuage for the St√§ubli TS60 industrial robot.

- **[Pick and Place Application with the St√§ubli TX60 Robot](https://github.com/yourusername/staubli-tx60-pick-place)**:
  
  A high-speed pick and place application for the St√§ubli TX60 robot in VAL3 language. 

- **[Kinematic Control System for a Mobile Manipulator](https://github.com/yourusername/mobile-manipulator-control)**:
  
  A control system for coordinating a mobile base with a robotic arm. Uses task-priority redundancy resolution for simultaneous navigation and manipulation. Addresses challenges in managing multiple degrees of freedom and avoiding singularities.

- **[Controlling a Swarm of Omnidirectional Robots Using Reynolds' Rules](https://github.com/yourusername/reynolds-swarm-control)**:
  
  Implementation of Reynolds' flocking rules for a group of omnidirectional robots. Applies principles of separation, alignment, and cohesion to achieve collective behavior. Tackles issues in distributed control and scalability to larger swarms.

- **[Design and Simulation of a SCARA Manipulator in ROS and Gazebo](https://github.com/yourusername/scara-manipulator-ros)**:
  
  A model of the St√§ubli TS60 SCARA robot arm modeled from scratch using URDF and simulated in ROS and Gazebo. 

## Computer Vision and Image Processing

- **[Integrated Machine Vision Application with the St√§ubli TX60 Robot](https://github.com/yourusername/staubli-tx60-vision)**:
  
  A machine vision system integrated with the St√§ubli TX60 robot. Uses ARUCO markers for object detection and pose estimation. 
  <!-- Tackles challenges in real-time processing and robust error handling in dynamic industrial environments. -->

- **[Stereo Visual Odometry on the KITTI Dataset](https://github.com/yourusername/stereo-visual-odometry)**:
  
  A stereo visual odometry system using the KITTI dataset. Implements feature extraction, matching, and motion estimation techniques. 
  <!-- Addresses challenges in handling diverse outdoor scenarios and maintaining accuracy over long distances. -->

- **[Feature Tracker Using ICP Algorithm for Event-based Pose Estimation](https://github.com/yourusername/event-based-feature-tracker)**:
  
  A feature tracking system for event-based cameras using the ICP algorithm. Enables pose estimation in high-speed and high-dynamic range scenarios. 
  <!-- Focuses on efficient processing of asynchronous event data and handling rapid motions. -->

- **[Camera Calibration, Pose Estimation, and AR using Aruco Markers](https://github.com/yourusername/aruco-pose-estimation)**:
  
  A system for camera calibration, pose estimation, and AR using Aruco markers. Implements marker detection and tracking algorithms in C++. 
  <!-- Addresses challenges in achieving real-time performance and handling marker occlusions. -->

- **[Underwater Image Analysis and Registration](https://github.com/yourusername/underwater-image-analysis)**:
  
  Techniques for analyzing and registering underwater images. Implements methods for color correction, visibility enhancement, and feature matching. 
  <!-- Tackles issues related to light attenuation, scattering, and low contrast in underwater environments. -->

- **[Epipolar Geometry and Stereo Vision Implementation](https://github.com/yourusername/epipolar-stereo-vision)**:
  
  Implementation of epipolar geometry and stereo vision algorithms. Covers camera calibration, rectification, disparity computation, and 3D reconstruction. 
  <!-- Addresses challenges in achieving accurate depth estimation and handling occlusions. -->

## AI and Machine Learning

- **[Explainable AI Module for Interpreting Object Detection Models](https://github.com/yourusername/xai-object-detection)**:
  
  An explainable AI module for object detection models in skin lesion detection. Implements local and global attribution techniques like Grad-CAM, SmoothGrad and LRP for generating explanations. Focuses on improving model interpretability in critical applications. 

- **[Pigmented Skin Lesion Detection Using Deep Learning](https://github.com/yourusername/skin-lesion-detection)**:
  
  A deep learning model for detecting pigmented skin lesions in clinical images. Utilizes transfer learning and data augmentation techniques. Addresses challenges in working with limited medical imaging datasets.
   <!-- and achieving high sensitivity. -->

- **[Semantic Segmentation of Pigmented Skin Lesions](https://github.com/yourusername/skin-lesion-segmentation)**:
  
  A semantic segmentation model for pigmented skin lesions. Adapts the U-Net architecture for precise lesion delineation. Tackles issues in handling irregular lesion shapes and achieving high boundary accuracy.

- **[Deep Learning Based Sentiment Analysis on SST Dataset](https://github.com/yourusername/sst-sentiment-analysis)**:
  
  A sentiment analysis model using the Stanford Sentiment Treebank dataset. Explores RNN, GRU, LSTM and transformer-based architectures. 
  <!-- Addresses challenges in capturing context and handling nuanced language expressions. -->

- **[Similarity Learning Using Metric Embedding](https://github.com/yourusername/metric-embedding-similarity)**:
  
  A similarity learning system using metric embedding techniques. Focuses on learning embeddings for complex data types like images and text. Tackles challenges in preserving semantic relationships in the embedding space.

- **[Hand-written Digit Classification on MNIST Dataset](https://github.com/yourusername/mnist-classification)**:
  
  A machine learning model for classifying hand-written digits. Compares various neural network architectures and optimization techniques. Addresses issues in handling variations in handwriting styles and achieving high accuracy.

- **[Image Classification on CIFAR Dataset](https://github.com/yourusername/cifar-classification)**:
  
  Deep learning models for image classification using the CIFAR dataset. Explores techniques like batch normalization and dropout. Focuses on balancing model complexity with computational efficiency.

- **[Facial Expression Recognition using Transfer Learning](https://github.com/yourusername/facial-expression-recognition)**:
  
  A facial expression recognition system using transfer learning with ResNet-18. Optimized for real-time performance on edge devices. Addresses challenges in handling varying lighting conditions and facial orientations.

## SLAM and Localization

- **[Implementation of EKF-SLAM with ICP Scan-matching](https://github.com/yourusername/ekf-slam-icp)**:
  
  An EKF-SLAM system integrated with ICP scan-matching. Uses 2D LiDAR and IMU sensors for localization and mapping. Tackles challenges in handling sensor uncertainties and achieving real-time performance in small environments.

- **[Feature-based SLAM Using Monocular Camera and Aruco Markers](https://github.com/yourusername/monocular-slam-aruco)**:
  
  A feature-based SLAM system using a monocular camera and Aruco markers. Implements efficient landmark detection and data association. 
  <!-- Addresses issues in scale ambiguity and loop closure detection. -->

- **[Stereo Visual Odometry Using UTIAS Dataset](https://github.com/yourusername/stereo-vo-utias)**:
  
  A stereo visual odometry system using the UTIAS dataset. Emphasizes robust feature tracking and motion estimation. 
  <!-- Focuses on handling challenging outdoor environments and maintaining long-term consistency. -->

- **[Particle Filter Algorithm for Kobuki Turtlebot Localization](https://github.com/yourusername/turtlebot-particle-filter)**:
  
  A particle filter-based localization system for the Kobuki Turtlebot. Implements efficient particle sampling and resampling strategies. 
  <!-- Addresses challenges in achieving real-time performance and handling dynamic obstacles. -->

## Motion Planning and Autonomous Systems

- **[Autonomous Robot Exploration Using Frontier-Based RRT*](https://github.com/yourusername/frontier-rrt-exploration)**:
  
  An autonomous exploration system combining Frontier-Based exploration with RRT* path planning. Implements the Dynamic Window approach for robot control. Tackles challenges in efficiently exploring unknown environments and avoiding local minima.

- **[Robot Pick and Place Task Using PDDL AI-Planner](https://github.com/yourusername/pddl-pick-place)**:
  
  A pick and place system using PDDL (Planning Domain Definition Language) for task planning. Generates optimal action sequences for multi-object manipulation. Addresses challenges in translating high-level plans to robot actions.

- **[Reinforcement Learning-Based Path Planning](https://github.com/yourusername/rl-path-planning)**:
  
  A reinforcement learning approach for robot path planning. Utilizes Q-learning method. Focuses on training agents to navigate efficiently in complex environments with obstacles.

- **[Implementation of A*, RRT, and RRT* Motion Planning Algorithms](https://github.com/yourusername/motion-planning-algorithms)**:
  
  Implementation of A*, RRT, and RRT* algorithms for robot motion planning. 
  <!-- Conducts performance analysis in various environments. Addresses trade-offs between computational efficiency and path optimality. -->

- **[Autonomous Exploration, Localization, Mapping, Perception, and Manipulation](https://github.com/yourusername/autonomous-robot-system)**:
  
  An integrated system for autonomous robot operation. Combines exploration, SLAM, perception, and manipulation capabilities. Tackles challenges in coordinating multiple subsystems for end-to-end autonomy.

## Multi-Robot Systems and Swarm Robotics

- **[Multi-Modal Human-Swarm Interaction](https://github.com/yourusername/multimodal-swarm-interaction)**:
  
  A system for human-swarm interaction using vision, speech, and multi-agent language models. Enables natural command and control of robot swarms. Addresses challenges in interpreting high-level instructions for swarm behavior.

- **[Robust Coordination and Control of Multi-Robot Systems Using Consensus Protocols](https://github.com/yourusername/multi-robot-consensus)**:
  
  Consensus protocol-based control strategies for multi-robot systems. Focuses on rendezvous and formation control using graph theory. Tackles issues in distributed control and scalability in various network topologies.

- **[ROS Package for Spawning Multiple Robots in Gazebo](https://github.com/yourusername/ros-multi-robot-spawn)**:
  
  A ROS package for spawning and managing multiple robots in Gazebo. Addresses challenges in efficiently simulating large-scale homogeneous multi-robot systems.
